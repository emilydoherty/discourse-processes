{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for free speech feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import nltk\n",
    "import torch\n",
    "import string\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from scipy import spatial\n",
    "from nltk.util import ngrams\n",
    "import tensorflow_hub as hub\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from statistics import mean, stdev\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# only if it has not been downloaded, uncomment:\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data \n",
    "# COLUMNS: \n",
    "# - FILE (a unique designator), \n",
    "# - TRANSCRIPT (human transcribed transcript)\n",
    "# - GROUP (1 = control, 2 = aMCI, 3 = AD)\n",
    "\n",
    "# DATA = pd.read_excel('Free_Speech.xlsx')\n",
    "# DATA = pd.read_excel\n",
    "makecode = pd.read_excel('/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned Transcripts/Makecode/Clean/makecode_master.xlsx')\n",
    "weights = pd.read_excel('/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned Transcripts/Weights/Clean/weights_master.xlsx')\n",
    "# change the column names to match above\n",
    "makecode = makecode.rename(columns={'Text':'TRANSCRIPT'}).astype(str)\n",
    "weights = weights.rename(columns={'Text':'TRANSCRIPT'}).astype(str)\n",
    "\n",
    "#pick makecode or weights \n",
    "DATA = makecode\n",
    "# DATA=weights\n",
    "#DATA = DATA.dropna(subset=['TRANSCRIPT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token and type count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA['participant_wc'] = DATA.apply(lambda row: len([x for x in row['TRANSCRIPT'].split() if x != '']), axis=1)\n",
    "DATA['participant_types'] = DATA.apply(lambda row: len(set([x for x in row['TRANSCRIPT'].split() if x != ''])), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_token_ratio = []\n",
    "\n",
    "for index, row in DATA.iterrows():\n",
    "    type_token_ratio.append(row['participant_types']/row['participant_wc'])\n",
    "    \n",
    "DATA['participant_type_token_ratio'] = type_token_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brunet's index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brunets_index = []\n",
    "\n",
    "for index, row in DATA.iterrows():\n",
    "    # log(wc**types**-0.165) = (types**-0.165)*log(wc)\n",
    "    brunets_index.append(row['participant_types']**(-0.165)*math.log(row['participant_wc']))\n",
    "\n",
    "DATA['participant_brunets_index'] = brunets_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count of ums ahs etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_ums_or_ahs = []\n",
    "participant_ums_or_ahs_freq = []\n",
    "\n",
    "for utterance, wc in zip(DATA.TRANSCRIPT, DATA.participant_wc):\n",
    "    total_ums_ahs = 0\n",
    "    for word in utterance.split():\n",
    "        # can include more here!\n",
    "        if word.lower() == 'um' or word.lower() == 'ah' or word.lower() == 'uh':\n",
    "            total_ums_ahs += 1\n",
    "\n",
    "    participant_ums_or_ahs.append(total_ums_ahs)\n",
    "    participant_ums_or_ahs_freq.append(total_ums_ahs/wc)\n",
    "    \n",
    "DATA['participant_ums_or_ahs_count'] = participant_ums_or_ahs\n",
    "DATA['participant_ums_or_ahs_freq'] = participant_ums_or_ahs_freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment of all sentences per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "participant_mean_sentiment = []\n",
    "participant_max_sentiment = []\n",
    "participant_min_sentiment = []\n",
    "participant_stdv_sentiment = []\n",
    "\n",
    "for transcript in DATA.TRANSCRIPT:\n",
    "    blob = TextBlob(transcript)\n",
    "    all_sentiments = [sentence.sentiment.polarity for sentence in blob.sentences]\n",
    "    participant_mean_sentiment.append(mean(all_sentiments))\n",
    "    participant_max_sentiment.append(max(all_sentiments))\n",
    "    participant_min_sentiment.append(min(all_sentiments))\n",
    "    try:\n",
    "        participant_stdv_sentiment.append(stdev(all_sentiments))\n",
    "    except:\n",
    "        participant_stdv_sentiment.append(0)\n",
    "\n",
    "DATA['participant_mean_sentiment'] = participant_mean_sentiment\n",
    "DATA['participant_max_sentiment'] = participant_max_sentiment\n",
    "DATA['participant_min_sentiment'] = participant_min_sentiment\n",
    "DATA['participant_stdv_sentiment'] = participant_stdv_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parts of speech frequencies per participant + content density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "participant_noun_freq = []\n",
    "participant_determiner_freq = []\n",
    "participant_preposition_freq = []\n",
    "participant_base_verb_freq = []\n",
    "participant_pasttense_verb_freq = []\n",
    "participant_gerund_presentparticiple_verb_freq = []\n",
    "participant_pastparticiple_verb_freq = []\n",
    "participant_non3rdpersonsingularpresent_verb_freq = []\n",
    "participant_3rdpersonsingularpresent_verb_freq = []\n",
    "participant_TOTAL_verb_freq = []\n",
    "participant_to_freq = []\n",
    "participant_adverb_freq = []\n",
    "participant_adjective_freq = []\n",
    "participant_modal_freq = []\n",
    "participant_coordinating_conjunctions_freq = []\n",
    "participant_cardinals_freq = []\n",
    "participant_particle_freq = []\n",
    "participant_personal_pronoun_freq = []\n",
    "participant_wh_adverbs_freq = []\n",
    "participant_possessive_pronoun_freq = []\n",
    "participant_wh_determiner_freq = []\n",
    "participant_predeterminer_freq = []\n",
    "participant_interjection_freq = []\n",
    "participant_existential_there_freq = []\n",
    "participant_wh_pronoun_freq = []\n",
    "participant_content_density = []\n",
    "\n",
    "for transcript, wc in zip(DATA.TRANSCRIPT, DATA.participant_wc):\n",
    "    blob = TextBlob(transcript)\n",
    "    nouns = 0\n",
    "    determiners = 0\n",
    "    prepositions = 0\n",
    "    base_verbs = 0\n",
    "    pasttense_verbs = 0\n",
    "    verb_gerund_presentparticiple = 0\n",
    "    verb_pastparticiple = 0\n",
    "    verb_non3rdpersonsingularpresent = 0\n",
    "    verb_3rdpersonsingularpresent = 0\n",
    "    tos = 0\n",
    "    adverbs = 0\n",
    "    adjectives = 0\n",
    "    modals = 0\n",
    "    coordinating_conjunctions = 0\n",
    "    cardinals = 0\n",
    "    particles = 0\n",
    "    personal_pronouns = 0\n",
    "    wh_adverbs = 0\n",
    "    possessive_pronouns = 0\n",
    "    wh_determiners = 0\n",
    "    predeterminers = 0\n",
    "    interjections = 0\n",
    "    existential_theres = 0\n",
    "    wh_pronouns = 0\n",
    "    \n",
    "    for word, tag in blob.tags:\n",
    "        #all nouns grouped together: singular, plural, proper singular, proper plural \n",
    "        if tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS':\n",
    "            nouns += 1\n",
    "        elif tag == 'DT':\n",
    "            determiners += 1\n",
    "        elif tag == 'IN':\n",
    "            prepositions += 1\n",
    "        elif tag == 'VB':\n",
    "            base_verbs +=1\n",
    "        elif tag == 'VBD':\n",
    "            pasttense_verbs += 1\n",
    "        elif tag == 'VBG':\n",
    "            verb_gerund_presentparticiple += 1\n",
    "        elif tag == 'VBN':\n",
    "            verb_pastparticiple += 1\n",
    "        elif tag == 'VBP':\n",
    "            verb_non3rdpersonsingularpresent += 1\n",
    "        elif tag == 'VBZ':\n",
    "            verb_3rdpersonsingularpresent += 1\n",
    "        elif tag == 'TO':\n",
    "            tos += 1\n",
    "        #all adverbs grouped together: normal, comparative, superlative\n",
    "        elif tag == 'RB' or tag == 'RBR' or tag == 'RBS':\n",
    "            adverbs += 1\n",
    "        #all adjectives grouped together: normal, comparative, superlative\n",
    "        elif tag == 'JJ' or tag == 'JJR' or tag == 'JJS':\n",
    "            adjectives += 1\n",
    "        elif tag == 'MD':\n",
    "            modals += 1\n",
    "        elif tag == 'CC':\n",
    "            coordinating_conjunctions += 1\n",
    "        elif tag == 'RP':\n",
    "            particles += 1\n",
    "        elif tag == 'CD':\n",
    "            cardinals += 1\n",
    "        elif tag == 'PRP':\n",
    "            personal_pronouns += 1\n",
    "        #when\n",
    "        elif tag == 'WRB':\n",
    "            wh_adverbs += 1  \n",
    "        elif tag == 'PRP$':\n",
    "            possessive_pronouns += 1\n",
    "        #that\n",
    "        elif tag == 'WDT':\n",
    "            wh_determiners += 1\n",
    "        elif tag == 'PDT':\n",
    "            predeterminers += 1\n",
    "        elif tag == 'UH':\n",
    "            interjections += 1\n",
    "        elif tag == 'EX':\n",
    "            existential_theres += 1\n",
    "        #who, what, whose\n",
    "        elif tag == 'WP' or tag == 'WP$':\n",
    "            wh_pronouns += 1\n",
    "            \n",
    "    total_verbs = base_verbs+pasttense_verbs+verb_gerund_presentparticiple+verb_pastparticiple+verb_non3rdpersonsingularpresent+verb_3rdpersonsingularpresent\n",
    "    participant_noun_freq.append(nouns/wc)\n",
    "    participant_determiner_freq.append(determiners/wc)\n",
    "    participant_preposition_freq.append(prepositions/wc)\n",
    "    participant_base_verb_freq.append(base_verbs/wc)\n",
    "    participant_pasttense_verb_freq.append(pasttense_verbs/wc)\n",
    "    participant_gerund_presentparticiple_verb_freq.append(verb_gerund_presentparticiple/wc)\n",
    "    participant_pastparticiple_verb_freq.append(verb_pastparticiple/wc)\n",
    "    participant_non3rdpersonsingularpresent_verb_freq.append(verb_non3rdpersonsingularpresent/wc)\n",
    "    participant_3rdpersonsingularpresent_verb_freq.append(verb_3rdpersonsingularpresent/wc)\n",
    "    participant_TOTAL_verb_freq.append(total_verbs/wc)\n",
    "    participant_to_freq.append(tos/wc)\n",
    "    participant_adverb_freq.append(adverbs/wc)\n",
    "    participant_adjective_freq.append(adjectives/wc)\n",
    "    participant_modal_freq.append(modals/wc)\n",
    "    participant_coordinating_conjunctions_freq.append(coordinating_conjunctions/wc)\n",
    "    participant_cardinals_freq.append(cardinals/wc)\n",
    "    participant_particle_freq.append(particles/wc)\n",
    "    participant_personal_pronoun_freq.append(personal_pronouns/wc)\n",
    "    participant_wh_adverbs_freq.append(wh_adverbs/wc)\n",
    "    participant_possessive_pronoun_freq.append(possessive_pronouns/wc)\n",
    "    participant_wh_determiner_freq.append(wh_determiners/wc)\n",
    "    participant_predeterminer_freq.append(predeterminers/wc)\n",
    "    participant_interjection_freq.append(interjections/wc)\n",
    "    participant_existential_there_freq.append(existential_theres/wc)\n",
    "    participant_wh_pronoun_freq.append(wh_pronouns/wc)\n",
    "    participant_content_density.append((total_verbs+nouns+adjectives+adverbs)/wc)\n",
    "    \n",
    "    \n",
    "DATA['participant_noun_freq'] = participant_noun_freq\n",
    "DATA['participant_determiner_freq'] = participant_determiner_freq\n",
    "DATA['participant_preposition_freq'] = participant_preposition_freq\n",
    "DATA['participant_base_verb_freq'] = participant_base_verb_freq\n",
    "DATA['participant_pasttense_verb_freq'] = participant_pasttense_verb_freq\n",
    "DATA['participant_gerund_presentparticiple_verb_freq'] = participant_gerund_presentparticiple_verb_freq\n",
    "DATA['participant_pastparticiple_verb_freq'] = participant_pastparticiple_verb_freq\n",
    "DATA['participant_non3rdpersonsingularpresent_verb_freq'] = participant_non3rdpersonsingularpresent_verb_freq\n",
    "DATA['participant_3rdpersonsingularpresent_verb_freq'] = participant_3rdpersonsingularpresent_verb_freq\n",
    "DATA['participant_TOTAL_verb_freq'] = participant_TOTAL_verb_freq\n",
    "DATA['participant_to_freq'] = participant_to_freq\n",
    "DATA['participant_adverb_freq'] = participant_adverb_freq\n",
    "DATA['participant_adjective_freq'] = participant_adjective_freq\n",
    "DATA['participant_modal_freq'] = participant_modal_freq\n",
    "DATA['participant_coordinating_conjunctions_freq'] = participant_coordinating_conjunctions_freq\n",
    "DATA['participant_cardinals_freq'] = participant_cardinals_freq\n",
    "DATA['participant_particle_freq'] = participant_particle_freq\n",
    "DATA['participant_personal_pronoun_freq'] = participant_personal_pronoun_freq\n",
    "DATA['participant_wh_adverbs_freq'] = participant_wh_adverbs_freq\n",
    "DATA['participant_possessive_pronoun_freq'] = participant_possessive_pronoun_freq\n",
    "DATA['participant_wh_determiner_freq'] = participant_wh_determiner_freq\n",
    "DATA['participant_predeterminer_freq'] = participant_predeterminer_freq\n",
    "DATA['participant_interjection_freq'] = participant_interjection_freq\n",
    "DATA['participant_existential_there_freq'] = participant_existential_there_freq\n",
    "DATA['participant_wh_pronoun_freq'] = participant_wh_pronoun_freq\n",
    "DATA['participant_content_density'] = participant_content_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coherence features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, load the embeddings you want to compute (comment out the ones you are not currently computing for memory purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_0:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_1:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_2:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en/sharded_3:0' shape=(47060, 320) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comment out anything you don't want to load for memory purposes! ##\n",
    "\n",
    "# USE model\n",
    "use_module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" \n",
    "use_model = hub.load(use_module_url)\n",
    "\n",
    "# # BERT model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
    "bert_model.eval()\n",
    "\n",
    "# bert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# def get_embedding_bert(text):\n",
    "#     text = text.replace(\"\\n\", \" \")\n",
    "#     embedding = bert_model.encode(text)\n",
    "#     return list(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, for memory purposes you cand delete the models you download AFTER you use them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del dcp_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions for coherence computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text, embedding_type):\n",
    "    '''\n",
    "    returns a single embedding (inter) or a list of embeddings (intra)\n",
    "    for a specified string and embedding_type\n",
    "    '''\n",
    "    \n",
    "    # universal sentence encoder\n",
    "    if embedding_type == 'USE_inter':\n",
    "        return use_model.signatures([text])[0]\n",
    "    \n",
    "    if embedding_type == 'USE_intra':\n",
    "        embeddings = []\n",
    "        for word in text.split():\n",
    "            embeddings.append(use_model([word])[0])\n",
    "        return embeddings\n",
    "    \n",
    "    # embeddings from language models - interwindow\n",
    "    elif embedding_type == 'ELMo_inter':\n",
    "        return elmo_model(tf.constant([text]))[\"default\"].numpy()[0]\n",
    "    \n",
    "    # embeddings from language models - intrawindow\n",
    "    elif embedding_type == 'ELMo_intra':\n",
    "        embeddings_tensor = elmo_model(tf.constant([text]))\n",
    "        word_embeddings = embeddings_tensor['word_emb'][0]\n",
    "        word_embeddings_unpacked = [x.numpy() for x in tf.unstack(word_embeddings)] \n",
    "        return word_embeddings_unpacked\n",
    "    \n",
    "    # BERT interwindow\n",
    "    elif embedding_type == 'BERT_inter':\n",
    "        # interwindow\n",
    "        tokenized_text = bert_tokenizer.encode(text)\n",
    "        # convert indexed tokens in a PyTorch tensor\n",
    "        input_ids = torch.tensor(tokenized_text).unsqueeze(0)\n",
    "        # run the input tensor through the BertModel\n",
    "        # see text in above cell for what is contained in outputs variable\n",
    "        outputs = bert_model(input_ids)\n",
    "        # get the last_hidden_state\n",
    "        last_hidden_state = outputs[0]\n",
    "        # last hidden state is dimension (batch_size, sequence_length, hidden_size)\n",
    "        # we have one batch so grab this single batch - this_batch is a tensor for each token in tokenized_text\n",
    "        this_batch = last_hidden_state[0]\n",
    "        #now get the 768 dimension vector for the CLS token (the first in the list) \n",
    "        cls_vector = this_batch[0].detach().numpy()\n",
    "        return cls_vector\n",
    "    \n",
    "    \n",
    "    \n",
    "    # BERT intrawindow\n",
    "    elif embedding_type == 'BERT_intra':\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        # Tokenize our sentence with the BERT tokenizer.\n",
    "        tokenized_text = bert_tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(tokens_tensor)\n",
    "            # Evaluating the model will return a different number of objects based on \n",
    "            # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "            # becase we set `output_hidden_states = True`, the third item will be the \n",
    "            # hidden states from all layers. See the documentation for more details:\n",
    "            # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "            hidden_states = outputs[2]\n",
    "            token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "            token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "            # Swap dimensions 0 and 1 so we can loop through the embeddings\n",
    "            token_embeddings = token_embeddings.permute(1,0,2)\n",
    "            # Stores the token vectors, with shape [N tokens x 768]\n",
    "            token_vecs_sum = []\n",
    "            # For each token in the sentence...\n",
    "            for token in token_embeddings[1:-1]:\n",
    "                # Sum the vectors from the last four layers.\n",
    "                sum_vec = torch.sum(token[-4:], dim=0)\n",
    "                # Use `sum_vec` to represent `token`.\n",
    "                token_vecs_sum.append(sum_vec)\n",
    "        return token_vecs_sum\n",
    "             \n",
    "    # word2vec: don't count, predict! \n",
    "    elif embedding_type == 'DCP_inter': \n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in dcp_embeddings:\n",
    "                vecs.append(dcp_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vector_sum(vecs)\n",
    "           \n",
    "    # word2vec: don't count, predict! \n",
    "    elif embedding_type == 'DCP_intra': \n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in dcp_embeddings:\n",
    "                vecs.append(dcp_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vecs\n",
    "            \n",
    "    # word2vec: google news \n",
    "    elif embedding_type == 'W2V_inter':\n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in w2v_embeddings.key_to_index:\n",
    "                vecs.append(w2v_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vector_sum(vecs)\n",
    "   \n",
    "    # word2vec: google news \n",
    "    elif embedding_type == 'W2V_intra':\n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in w2v_embeddings.key_to_index:\n",
    "                vecs.append(w2v_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vecs\n",
    "            \n",
    "    # GloVe\n",
    "    elif embedding_type == 'GloVe_inter':\n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in glove_embeddings:\n",
    "                vecs.append(glove_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vector_sum(vecs)\n",
    "   \n",
    "    # GloVe\n",
    "    elif embedding_type == 'GloVe_intra':\n",
    "        words = str(text).translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        vecs = []\n",
    "        for word in words.split():\n",
    "            if word in glove_embeddings:\n",
    "                vecs.append(glove_embeddings[word])\n",
    "        if len(vecs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return vecs\n",
    "\n",
    "    else:\n",
    "        print('Incorrect embedding type')\n",
    "        return None\n",
    "        \n",
    "        \n",
    "def vector_sum(vectors):\n",
    "    '''\n",
    "    given a list of vectors for a sentence, return the sum of all vectors\n",
    "    this is used to create ngram+ embeddings for non-contextualized embedding types\n",
    "    '''\n",
    "    n = len(vectors)\n",
    "    d = len(vectors[0])\n",
    "\n",
    "    #create an array initialized to 0 of the same length of the word embeddings\n",
    "    s = [0 for i in range(d)]\n",
    "\n",
    "    #add each word embedding to the zero vector\n",
    "    for vector in vectors:\n",
    "        s = s + np.array(vector)\n",
    "\n",
    "    return list(s)\n",
    "\n",
    "\n",
    "def get_intra_window_cosines(text, embedding_type):\n",
    "    '''\n",
    "    iterate through a window comparing each word to each other word\n",
    "    '''\n",
    "    \n",
    "    all_embeddings = embed(text, embedding_type+'_intra')\n",
    "    \n",
    "    if all_embeddings:\n",
    "        if len(all_embeddings) < 2:\n",
    "            return None\n",
    "\n",
    "        all_cosines = []\n",
    "        for a, b in itertools.combinations(all_embeddings, 2):\n",
    "            cos = 1 - spatial.distance.cosine(a, b)\n",
    "            all_cosines.append(cos)\n",
    "\n",
    "        return all_cosines\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_inter_window_cosine(text1, text2, embedding_type):\n",
    "    \n",
    "    e1 = embed(text1, embedding_type+'_inter')\n",
    "    e2 = embed(text2, embedding_type+'_inter')\n",
    "    if embedding_type == 'USE' or embedding_type == 'ELMo' or embedding_type == 'BERT':\n",
    "        return 1 - spatial.distance.cosine(e1, e2)\n",
    "\n",
    "    else:\n",
    "        if e1 and e2:\n",
    "            return 1 - spatial.distance.cosine(e1, e2)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "def get_ngrams(text, n):\n",
    "    '''\n",
    "    return a list of n-grams\n",
    "    '''\n",
    "\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    \n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "\n",
    "def get_slope(nums):\n",
    "    '''\n",
    "    compute the slope of a list of cosines\n",
    "    '''\n",
    "    x = range(len(nums))\n",
    "    y = nums\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### between window coherence (interwindow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_module_url =\"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "use_model = hub.load(use_module_url)\n",
    "def get_embedding_USE(text):\n",
    "    embedding = use_model.signatures(text)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding='BERT'\n",
    "num_utterances=len(DATA.TRANSCRIPT)\n",
    "cosines=[]\n",
    "mean_coherence = []\n",
    "std_coherence = []\n",
    "min_coherence = []\n",
    "max_coherence = []\n",
    "slope_coherence = []\n",
    "for i in range(num_utterances-1):\n",
    "    res= get_inter_window_cosine(DATA.TRANSCRIPT[i], DATA.TRANSCRIPT[i+1], embedding)\n",
    "    if res:\n",
    "        cosines.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosines.insert(0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[f'coherence_{embedding}_interwindow'] = cosines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (5275) does not match length of index (5276)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned Transcripts/Code/Chelseas_code_ED.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned%20Transcripts/Code/Chelseas_code_ED.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m DATA[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_coherence_\u001b[39;49m\u001b[39m{\u001b[39;49;00membedding\u001b[39m}\u001b[39;49;00m\u001b[39m_interwindow\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m mean_coherence\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned%20Transcripts/Code/Chelseas_code_ED.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m DATA[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstd_coherence_\u001b[39m\u001b[39m{\u001b[39;00membedding\u001b[39m}\u001b[39;00m\u001b[39m_interwindow\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m std_coherence\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emilydoherty/Library/CloudStorage/OneDrive-UCB-O365/Emily_Papers/iSAT_discoursepaper2023/Cleaned%20Transcripts/Code/Chelseas_code_ED.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m DATA[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin_coherence_\u001b[39m\u001b[39m{\u001b[39;00membedding\u001b[39m}\u001b[39;00m\u001b[39m_interwindow\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m min_coherence\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (5275) does not match length of index (5276)"
     ]
    }
   ],
   "source": [
    "DATA[f'mean_coherence_{embedding}_interwindow'] = mean_coherence\n",
    "DATA[f'std_coherence_{embedding}_interwindow'] = std_coherence\n",
    "DATA[f'min_coherence_{embedding}_interwindow'] = min_coherence\n",
    "DATA[f'max_coherence_{embedding}_interwindow'] = max_coherence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT \n",
    "## loading this here because they have the same name as the \n",
    "## previous (different) BERT tokenizer \n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    bert_model = BertForMaskedLM.from_pretrained('bert-large-cased')\n",
    "    bert_model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    \n",
    "def get_BERT_score(sentence):\n",
    "    tokenize_input = bert_tokenizer.tokenize(sentence)\n",
    "    tokenize_input = [\"[CLS]\"]+tokenize_input+[\"[SEP]\"]\n",
    "    tensor_input = torch.tensor([bert_tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    with torch.no_grad():\n",
    "        loss = bert_model(tensor_input, labels=tensor_input)[0]\n",
    "    return np.exp(loss.detach().numpy())\n",
    "\n",
    "# GPT 2\n",
    "with torch.no_grad():\n",
    "    gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    gpt2_model.eval()\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    " \n",
    "def get_GPT_score(sentence):\n",
    "    tokenize_input = gpt2_tokenizer.encode(sentence)\n",
    "    tensor_input = torch.tensor([tokenize_input])\n",
    "    loss = gpt2_model(tensor_input, labels=tensor_input)[0]\n",
    "    return np.exp(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 'BERT' # swap out for GPT2\n",
    "\n",
    "avg_sentence_probabilities = []\n",
    "min_sentence_probabilities = []\n",
    "max_sentence_probabilities = []\n",
    "stdv_sentence_probabilities = []\n",
    "firstquartile_sentence_probabilities = []\n",
    "median_sentence_probabilities = []\n",
    "thirdquartile_sentence_probabilities = []\n",
    "\n",
    "for utterance in DATA.TRANSCRIPT:\n",
    "\n",
    "    all_utterances = utterance.lower()\n",
    "    \n",
    "    sentences = sent_tokenize(all_utterances)\n",
    "    \n",
    "    sentence_probs = []\n",
    "\n",
    "    if embedding == 'BERT':\n",
    "        for text in sentences:\n",
    "            if len(text.split()) > 2:\n",
    "                sentence_probs.append(get_BERT_score(text))\n",
    "                \n",
    "    elif embedding == 'GPT2':\n",
    "        for text in sentences:\n",
    "            if len(text.split()) > 2:\n",
    "                sentence_probs.append(get_GPT_score(text))\n",
    "                \n",
    "    else:\n",
    "        print('incorrect embedding type')\n",
    "        break\n",
    "                \n",
    "    if len(sentence_probs) > 0:\n",
    "        firstquartile_sentence_probabilities.append(np.percentile(sentence_probs, 25))\n",
    "        median_sentence_probabilities.append(np.percentile(sentence_probs, 50))\n",
    "        thirdquartile_sentence_probabilities.append(np.percentile(sentence_probs, 75))\n",
    "        avg_sentence_probabilities.append(np.array(sentence_probs).mean())\n",
    "        min_sentence_probabilities.append(min(sentence_probs))\n",
    "        max_sentence_probabilities.append(max(sentence_probs))\n",
    "        stdv_sentence_probabilities.append(np.array(sentence_probs).std())\n",
    "    else:\n",
    "        # there were no sentences > 2 words...\n",
    "        firstquartile_sentence_probabilities.append(np.nan)\n",
    "        median_sentence_probabilities.append(np.nan)\n",
    "        thirdquartile_sentence_probabilities.append(np.nan)\n",
    "        avg_sentence_probabilities.append(np.nan)\n",
    "        min_sentence_probabilities.append(np.nan)\n",
    "        max_sentence_probabilities.append(np.nan)\n",
    "        stdv_sentence_probabilities.append(np.nan)  \n",
    "        \n",
    "DATA[f'mean_sentence_probability_{embedding}'] = avg_sentence_probabilities\n",
    "DATA[f'min_sentence_probability_{embedding}'] = min_sentence_probabilities\n",
    "DATA[f'max_sentence_probability_{embedding}'] = max_sentence_probabilities\n",
    "DATA[f'stdv_sentence_probability_{embedding}'] = stdv_sentence_probabilities\n",
    "DATA[f'firstquartile_sentence_probability_{embedding}'] = firstquartile_sentence_probabilities\n",
    "DATA[f'median_sentence_probability_{embedding}'] = median_sentence_probabilities\n",
    "DATA[f'thirdquartile_sentence_probability_{embedding}'] = thirdquartile_sentence_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.to_excel('Free_Speech_Features_Final.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the f statistics for individual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in DATA.columns:\n",
    "    \n",
    "    if column != 'FILE' and column != 'TRANSCRIPT' and column != 'GROUP' and column != 'participant_parse_depth_per_sentence':\n",
    "        \n",
    "        ones = DATA[DATA.GROUP=='HC']\n",
    "        twos = DATA[DATA.GROUP=='aMCI']\n",
    "        threes = DATA[DATA.GROUP=='AD']\n",
    "        twosthrees = DATA[(DATA.GROUP=='aMCI')|(DATA.GROUP=='AD')]\n",
    "        \n",
    "        f1, p1 = stats.f_oneway(ones[column].dropna(), twos[column].dropna(), threes[column].dropna())\n",
    "        f2, p2 = stats.f_oneway(ones[column].dropna(), twos[column].dropna())\n",
    "        f3, p3 = stats.f_oneway(ones[column].dropna(), threes[column].dropna())\n",
    "        f4, p4 = stats.f_oneway(twos[column].dropna(), threes[column].dropna())\n",
    "        f5, p5 = stats.f_oneway(ones[column].dropna(), twosthrees[column].dropna())\n",
    "\n",
    "        print(column, 'overall', (f1,p1), '1vs2', (f2,p2),'1vs3', (f3,p3),'2vs3', (f4,p4), '1vs23', (f5,p5))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
